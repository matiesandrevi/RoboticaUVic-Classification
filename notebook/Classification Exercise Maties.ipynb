{
 "metadata": {
  "name": "",
  "signature": "sha256:b9c1649c27b9d63251fd7e1f6bace22ddea5fc5cfff054dcf71af0199074dc01"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Q1 K-Nearest Neighbors   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy.spatial.distance as dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "from collections import Counter\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import LinearSVC, SVC\n",
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#you will need to download the data and labels from there\n",
      "data = np.array([map(float, x.split(',')[:-1]) for x in open('iris.data') if x.strip()!=''])\n",
      "labels = np.array([x.split(',')[-1].strip() for x in open('iris.data') if x.strip()!=''])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Use the train/test partition indicated by the indexes 'iris_idx_train.txt' and 'iris_idx_test.txt'\n",
      "iris_idx_train = np.loadtxt('iris_idx_train.txt')\n",
      "iris_idx_test = np.loadtxt('iris_idx_test.txt')\n",
      "iris_idx_train = iris_idx_train.astype(int)\n",
      "iris_idx_test = iris_idx_test.astype(int)\n",
      "# Data\n",
      "iris_data_train = data[iris_idx_train,:]\n",
      "iris_data_test = data[iris_idx_test,:]\n",
      "# Labels\n",
      "iris_labels_train = labels[iris_idx_train]\n",
      "iris_labels_test = labels[iris_idx_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Q1 Implement a function that does kNN classification, and use it to classify the Iris dataset\n",
      "#Plot the accuracy for all odd values of k from 1 to 9.\n",
      "def runknn(tr_data, tr_labels, te_data, te_labels):\n",
      "    for k in range(1,9):\n",
      "\n",
      "        knn = KNeighborsClassifier(k)\n",
      "        #Training process with the training data\n",
      "        knn.fit(iris_data_train, iris_labels_train)\n",
      "        # See the accuracy score\n",
      "        acc = knn.score(iris_data_test, iris_labels_test)\n",
      "        print 'Accuracy (k=%d): %.4f'%(k,acc)\n",
      "\n",
      "runknn(iris_data_train, iris_labels_train, iris_data_test, iris_labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy (k=1): 0.9400\n",
        "Accuracy (k=2): 0.9400\n",
        "Accuracy (k=3): 0.9400\n",
        "Accuracy (k=4): 0.9400\n",
        "Accuracy (k=5): 0.9600\n",
        "Accuracy (k=6): 0.9400\n",
        "Accuracy (k=7): 0.9600\n",
        "Accuracy (k=8): 0.9400\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def runknn2(tr_data, tr_labels, te_data, te_labels):\n",
      "    for k in range(1,9):\n",
      "        distance=dist.cdist(tr_data, te_data)\n",
      "        k_min = np.argsort(distance.T,1)[:,1:k+1]\n",
      "        lebel_min = tr_labels [k_min]\n",
      "        accuracy = accuracy_score(te_labels, [Counter(x).most_common()[0][0] for x in lebel_min] )\n",
      "        \n",
      "        print 'Accuracy (k=%d): %.4f'%(k,accuracy)\n",
      "\n",
      "runknn2(iris_data_train, iris_labels_train, iris_data_test, iris_labels_test)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy (k=1): 0.9400\n",
        "Accuracy (k=2): 0.9400\n",
        "Accuracy (k=3): 0.9400\n",
        "Accuracy (k=4): 0.9400\n",
        "Accuracy (k=5): 0.9600\n",
        "Accuracy (k=6): 0.9600\n",
        "Accuracy (k=7): 0.9600\n",
        "Accuracy (k=8): 0.9400\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Q2 Logistic Regression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = list(range(1, 16))\n",
      "B = list(range(1, 16))\n",
      "p = 0\n",
      "data_training = np.load('3dclothing_train.npy')\n",
      "data_testing = np.load('3dclothing_test.npy')\n",
      "\n",
      "labels_training = np.array([x.strip() for x in open('3dclothing_labels_train.txt')])\n",
      "labels_testing = np.array([x.strip() for x in open('3dclothing_labels_test.txt')])\n",
      "\n",
      "ok_data_training = data_training[(labels_training == 'shirt') + (labels_training == 'jeans'),:]\n",
      "ok_data_testing = data_testing[(labels_testing == 'shirt') + (labels_testing == 'jeans'),:]\n",
      "\n",
      "ok_labels_training = labels_training[(labels_training == 'shirt') + (labels_training == 'jeans')]\n",
      "ok_labels_testing = labels_testing[(labels_testing == 'shirt') + (labels_testing == 'jeans')]\n",
      "\n",
      "for i in xrange (-7,8):    \n",
      "    LogReg = LogisticRegression(C=10**i)\n",
      "    A[p]=i\n",
      "    LogReg.fit(ok_data_training, ok_labels_training)\n",
      "    B[p] = LogReg.score(ok_data_testing, ok_labels_testing)\n",
      "    print 'Logistic Regression accuracy for C = 10^', i, ' is ', B[p]\n",
      "    p+=1\n",
      "\n",
      "pl.plot(A[:14],B[:14])\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Q3 Now, train a multi-class Logistic Regression classifier with the complete training set. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = list(range(1, 8))\n",
      "B = list(range(1, 8))\n",
      "p = 0\n",
      "data_training = np.load('3dclothing_train.npy')\n",
      "data_testing = np.load('3dclothing_test.npy')\n",
      "\n",
      "labels_training = np.array([x.strip() for x in open('3dclothing_labels_train.txt')])\n",
      "labels_testing = np.array([x.strip() for x in open('3dclothing_labels_test.txt')])\n",
      "\n",
      "for i in xrange (-3,4):    \n",
      "    LogReg = LogisticRegression(C=10**i)\n",
      "    A[p]=i\n",
      "    LogReg.fit(data_training, labels_training)\n",
      "    B[p] = LogReg.score(data_testing, labels_testing)\n",
      "    print 'Logistic Regression accuracy for C = 10^', i, ' is ', B[p]\n",
      "    p+=1\n",
      "    \n",
      "pl.plot(A[:5],B[:5])\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Q4 Sometimes we want to re-use a trained classified in another system, or with another programming language"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_training = np.load('3dclothing_train.npy')\n",
      "data_testing = np.load('3dclothing_test.npy')\n",
      "\n",
      "labels_training = np.array([x.strip() for x in open('3dclothing_labels_train.txt')])\n",
      "labels_testing = np.array([x.strip() for x in open('3dclothing_labels_test.txt')])\n",
      "\n",
      "ok_data_testing = data_testing[(labels_testing == 'shirt') + (labels_testing == 'jeans'),:]\n",
      "ok_data_training = data_training[(labels_training == 'shirt') + (labels_training == 'jeans'),:]\n",
      "\n",
      "ok_labels_training = labels_training[(labels_training == 'shirt') + (labels_training == 'jeans')]\n",
      "ok_labels_testing = labels_testing[(labels_testing == 'shirt') + (labels_testing == 'jeans')]\n",
      "\n",
      "for i in xrange (-7,8):    \n",
      "    LogReg = LogisticRegression(C=10**i)\n",
      "    LogReg.fit(ok_data_training, ok_labels_training)\n",
      "    a = LogReg.score(ok_data_testing, ok_labels_testing)\n",
      "    #Intercept (a.k.a. bias) added to the decision function. \n",
      "    #If fit_intercept is set to False, the intercept is set to zero.\n",
      "    bias = LogReg.intercept_\n",
      "    #Coefficient of the features in the decision function.\n",
      "    theta = LogReg.coef_\n",
      "    #y = 1/(1+e^-(xo+b))\n",
      "    accuracy = 1/(1+(np.exp(-np.dot(ok_data_testing, theta.T)-bias)))\n",
      "\n",
      "print 'Important information to re-use a trained classified in another system are bias and theta.'\n",
      "print 'New accuracy is', accuracy\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Q5 Support Vector Machines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Adapted from: Gael Varoquaux, Andreas Muller; \"Classifier comparison\"  \n",
      "#http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html  \n",
      "\n",
      "def paint_decision_functions(data, labels, clf):  \n",
      "    from matplotlib.colors import ListedColormap  \n",
      "    import pylab  \n",
      "    cm = pylab.cm.RdBu  \n",
      "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])  \n",
      "    x_min, x_max = data[:, 0].min() - .5, data[:, 0].max() + .5  \n",
      "    y_min, y_max = data[:, 1].min() - .5, data[:, 1].max() + .5  \n",
      "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),  \n",
      "                         np.arange(y_min, y_max, 0.1))  \n",
      "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])  \n",
      "    Z = Z.reshape(xx.shape)  \n",
      "    pylab.contourf(xx, yy, Z, cmap=cm, alpha=.8)  \n",
      "    pylab.scatter(data[:, 0], data[:, 1], c=labels, cmap=cm_bright)  \n",
      "    pylab.xlim(xx.min(), xx.max())  \n",
      "    pylab.ylim(yy.min(), yy.max())  \n",
      "    pylab.xticks(())  \n",
      "    pylab.yticks(())  \n",
      "    pylab.show()\n",
      "\n",
      "data = np.loadtxt('jain.txt')\n",
      "\n",
      "all_data = data[:,:-1]\n",
      "labels = data[:,-1]\n",
      "\n",
      "l = len(data)/2\n",
      "\n",
      "#Randomly permute a sequence, or return a permuted range.\n",
      "x = np.random.permutation(data.shape[0])\n",
      "\n",
      "data_training = all_data[x[:l],:]\n",
      "data_testing = all_data[x[:l],:]\n",
      "\n",
      "labels_training = labels[x[:l]]\n",
      "labels_testing = labels[x[:l]]\n",
      "\n",
      "y = LinearSVC()\n",
      "y.fit(data_training, labels_training)\n",
      "a = y.score(data_testing, labels_testing)\n",
      "print 'Support Vector Machine: ', a\n",
      "\n",
      "\n",
      "yg = SVC()\n",
      "yg.fit(data_training, labels_training)\n",
      "b = yg.score(data_testing, labels_testing)\n",
      "print 'SVM with a Gaussian Radial Basis Function Kernel: ', b \n",
      "\n",
      "paint_decision_functions(data_testing, labels_testing, y)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/maties/.local/lib/python2.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
        "  \"the number of iterations.\", ConvergenceWarning)\n",
        "/home/maties/.local/lib/python2.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
        "  \"avoid this warning.\", FutureWarning)\n",
        "/home/maties/.local/lib/python2.7/site-packages/numpy/ma/core.py:6462: MaskedArrayFutureWarning: In the future the default for ma.maximum.reduce will be axis=0, not the current None, to match np.maximum.reduce. Explicitly pass 0 or None to silence this warning.\n",
        "  return self.reduce(a)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Support Vector Machine:  0.9193548387096774\n",
        "SVM with a Gaussian Radial Basis Function Kernel:  1.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/maties/.local/lib/python2.7/site-packages/numpy/ma/core.py:6462: MaskedArrayFutureWarning: In the future the default for ma.minimum.reduce will be axis=0, not the current None, to match np.minimum.reduce. Explicitly pass 0 or None to silence this warning.\n",
        "  return self.reduce(a)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Q8 Classifier Evaluation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q8 Variables - Threshold is at 0.5\n",
      "fries_labels = np.load('robot_waiter_fries_labels.npy')\n",
      "fries_scores = np.load('robot_waiter_fries_scores.npy')\n",
      "Total_data = 150000\n",
      "\n",
      "True_fries = fries_scores > 0.5\n",
      "\n",
      "#Predictions \n",
      "P = Total_data\n",
      "#True_positive \n",
      "TP = float(sum(True_fries & fries_labels))\n",
      "#False_positive \n",
      "FP = float(sum(True_fries & -fries_labels))\n",
      "#False_negative \n",
      "FN = float(sum(-True_fries & fries_labels))\n",
      "#True_negative\n",
      "TN = float(sum(-True_fries & -fries_labels))\n",
      "\n",
      "In [ ]:\n",
      "\n",
      "#Q8_1 Accuracy and Error Rate\n",
      "\n",
      "#Accuracy = correct predictions(TP+TN)/#predictions\n",
      "Accuracy = (TP+TN)/P\n",
      "#Error Rate = incorrect predictions(FP+FN)/#predictions\n",
      "Error_Rate = (FP+FN)/P\n",
      "\n",
      "print 'Accuracy is', Accuracy\n",
      "print 'Error Rate is', Error_Rate\n",
      "\n",
      "In [ ]:\n",
      "\n",
      "#Q8_2 Balanced Error Rate \n",
      "\n",
      "#True Positive Rate: TPR \n",
      "TPR = TP/(TP+FN)\n",
      "\n",
      "#True Negative Rate: TNR\n",
      "TNR = TN/(FP+TN)\n",
      "\n",
      "#Balanced Error Rate: BER\n",
      "BER = 1-0.5*(TPR + TNR)\n",
      "\n",
      "print 'Balanced Error Rate is', BER\n",
      "\n",
      "In [ ]:\n",
      "\n",
      "#Q8_3\n",
      "\n",
      "Precision = TP/(TP+FP)\n",
      "Recall = TP/(TP+FN)\n",
      "F1 = 2*((Precision*Recall)/(Precision+Recall))\n",
      "\n",
      "print 'F1-score is', F1\n",
      "\n",
      "In [ ]:\n",
      "\n",
      "#Q8_4 Compute the f-beta score with beta=0.5\n",
      "\n",
      "beta = 0.5\n",
      "Fbeta = (1+beta**2)*((Precision*Recall)/(beta**2*Precision+Recall))\n",
      "\n",
      "print 'F-beta score is', Fbeta\n",
      "\n",
      "In [ ]:\n",
      "\n",
      "#Q8_5 plot the precision-recall curve for our classifier.\n",
      "\n",
      "precision, recall, _ = precision_recall_curve(fries_labels, fries_scores)\n",
      "\n",
      "pl.plot(recall, precision)\n",
      "pl.show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}